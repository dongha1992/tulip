import re
from collections import Counter


# í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œ ì œì™¸í•  ì¡°ì‚¬Â·ëŒ€ëª…ì‚¬Â·í”í•œ ë‹¨ì–´ (ì˜ë¯¸ ìˆëŠ” í‚¤ì›Œë“œë§Œ ë‚¨ê¸°ê¸° ìœ„í•¨)
STOPWORDS = {
    # ì¡°ì‚¬Â·ì–´ë¯¸
    "ì€",
    "ëŠ”",
    "ì´",
    "ê°€",
    "ì„",
    "ë¥¼",
    "ì˜",
    "ì—",
    "ì™€",
    "ê³¼",
    "ë„",
    "ë§Œ",
    "ì—ì„œ",
    "ìœ¼ë¡œ",
    "ë¡œ",
    "í•œ",
    "í•˜ë‹¤",
    "ìˆë‹¤",
    "ë˜ë‹¤",
    # ëŒ€ëª…ì‚¬Â·ì§€ì‹œì–´Â·ë¶€ì‚¬ ë“± (ì˜ë¯¸ ì•½í•œ ë‹¨ì–´)
    "ê·¸",
    "ì´",
    "ì €",
    "ê·¸ê²ƒ",
    "ì´ê²ƒ",
    "ì €ê²ƒ",
    "ë‚˜",
    "ë„ˆ",
    "ìš°ë¦¬",
    "ìš°ë¦°",
    "ë„ˆë„¤",
    "ë„ˆí¬",
    "ë‚˜ë„",
    "ë„ˆë„",
    "ë„ˆë‚˜",
    "ìê¾¸",
    "ê·¸ëƒ¥",
    "ì§„ì§œ",
    "ì •ë§",
    "ë„ˆë¬´",
    "ì™„ì „",
    "ì¢€",
    "ë­ì•¼",
    "ë­ì§€",
    "ê·¸ëŸ¼",
    "ì´ì œ",
    "ë‹¤ì‹œ",
    "í•­ìƒ",
    "ë§¨ë‚ ",
    # ì˜ì–´ ë¶ˆìš©ì–´
    "ë¬´ì—‡",
    "ì–´ë–¤",
    "ì–´ë””",
    "ì–¸ì œ",
    "ì™œ",
    "how",
    "the",
    "a",
    "an",
    "is",
    "are",
    "was",
    "were",
    "to",
    "of",
    "in",
    "on",
    "for",
    "and",
    "or",
    "but",
}


class SentimentAnalyzer:
    def __init__(self):
        # ê°ì • ì‚¬ì „ ì •ì˜ (ê°€ë³ê³  ë¹ ë¥¸ ë£° ê¸°ë°˜ ë¶„ì„ì— ì‚¬ìš©)
        self.EMOTION_DICT = {
            'positive': [
                'ê°ì‚¬','ë‹´ëŠ”ë‹¤','ì—…','íšŒë³µ', 'ë¶ˆì¥','ë§¤ìˆ˜', 'ğŸ‘ğŸ»', 'í˜¸ì¬', 'ì™€', 'ìœë‹¤', 'ì´ë¼',
                'ê°€ì¦ˆì•„', 'ê°€ë³´ì', 'ê°€ì', 'ê°„ë‹¤', 'ë–¡ìƒ', 'ëŒ€ë°•', 'ë¡œì¼“', 'í™”ì„±', 'ê³ ê³ ',
                'í•œê°•ë·°', 'íˆ¬ë”ë¬¸', 'ë‹¤í–‰','êµ¿', 'ì¢‹ë‹¤','ì˜¤'
            ],
            'negative': [
                'ã… ', 'ã…œ', 'ã…¡', 'ã…—', 'í•˜..', 'í•˜...', 'í..', 'í‘..', 'í—..','ì—íœ´',
                'í—ˆê±±', 'í—‰', 'í‘í‘', 'í•˜ì•„', 'í•˜..', 'ì•Šë‹¤', 'ì—†ë‹¤', 'ì•„ë‹ˆë‹¤','í•œê°•',
                'ë–¨ì–´ì§„ë‹¤', 'í­ë½', 'ì†ì‹¤', 'ì†ì ˆ', 'ë¹š', 'í•˜ë½', 'í•˜í•œê°€', 'ì¡´ë²„', 'ì¡´ë²„ì¤‘',
                'íƒˆì¶œ', 'ë¦¬ìŠ¤í¬', 'ìœ„í—˜', 'ë¶ˆì•ˆ', 'ê±±ì •', 'ë‹µì´ì—†', 'ë§í–ˆ', 'í„¸ë ¸', 'ì¡°ì •',
                'í•˜ë½ì¥', 'ì•½ì„¸ì¥','ì‚´ë ¤ì¤˜', 'ì‹¬ë€','íšŒì˜ì ', 'ê³¡ì†Œë¦¬', 'ë¹šíˆ¬', 'ì†ì‹¤',
                'ì‚´ë ¤ì¤˜', 'ì†í•´','ì¡ì£¼','ë§í–ˆë‹¤', 'í­ë§', 'ëŒ€í­ë½', 'ê³µí¬','ìŠ¤íŠ¸ë ˆìŠ¤',
                'ë–¨ì–´ì§€ë©´','ëŸ´', 'íŒ¨ë‹‰ì…€','ê°œë¬´ì„­ë„¤','ì¡°ì§„','ê³ ì ì‹ í˜¸','ì£½ì‘¤ê³ ','ì„¤ê±°ì§€','ìŒ','í '
            ],
            'very_negative': [
                'ìœ¼ì•„', 'ì‚´ë ¤', 'í•˜..', 'í•˜...', 'í‘..', 'í—..', 'ì—íœ´','í•œê°•ê°€ì',
                'í•œê°•ë¬¼', 'ì–´íœ´', 'ìƒí', 'ì‚­ì œ','ã…¡ã…¡','ìˆ¨ê¹€','ì•ˆë¼','ì•ˆë¼ìš”','ì•ˆë¼',
            ],
            'swear_words': [
                'ã……ã…‚', 'ã…‚ã……', 'ã…ˆã„¹', 'ã…ã…Š', 'ã……ã„²','ã…ˆã„´', 'ã…—ã…—',
                'ê°œã……ã„²', 'ê°œã…‚ã……', 'ê°œã…ˆã„¹', 'ê°œã……ã…‚','ê°œã…ã…Š', 'ë ¨',
                'ì§€ã„¹', 'ë‹¥ã…Š', 'ã……ã„²ë“¤', 'ã…‚ã……ë“¤', 'ã…ˆã„¹í•˜ë„¤',
                'ë¯¸ã…Š', 'ë¹¡ì¹˜', 'ê°œìƒˆ', 'ì‹­', 'ì‹œã…‚', 'ë³‘ã……'
            ]
        }

        self.LABEL_MAPPING = {
            0: "ë¶€ì •",
            1: "ë‹¤ì†Œ ë¶€ì •",
            2: "ì¤‘ë¦½",
            3: "ë‹¤ì†Œ ê¸ì •",
            4: "ê¸ì •"
        }

    def preprocess_text(self, text):
        text = text.lower()
        text = re.sub(r'\s+', ' ', text)
        return text.strip()

    def extract_emotion_features(self, text):
        text = self.preprocess_text(text)
        has_positive = any(em in text for em in self.EMOTION_DICT['positive'])
        has_negative = any(em in text for em in self.EMOTION_DICT['negative'])
        has_very_negative = any(em in text for em in self.EMOTION_DICT['very_negative'])
        has_swear = any(em in text for em in self.EMOTION_DICT['swear_words'])
        return has_positive, has_negative, has_very_negative, has_swear

    def _score_with_rules(self, text: str) -> float:
        """
        BERT ëŒ€ì‹  ê°€ë²¼ìš´ ë£° ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°.
        - ê¸°ë³¸ 50ì ì—ì„œ ì‹œì‘
        - positive / negative / very_negative / swear_words ì‚¬ì „ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ë¶€ì—¬
        """
        has_positive, has_negative, has_very_negative, has_swear = self.extract_emotion_features(
            text
        )

        score = 50.0

        # ìš•ì„¤ì´ ìˆìœ¼ë©´ ê°•í•œ ë¶€ì •
        if has_swear:
            score = 5.0
        else:
            if has_positive:
                score += 20
            if has_negative:
                score -= 20
            if has_very_negative:
                score -= 35

            # ê°•í•œ ê¸ì • í‘œí˜„ ë³´ì •
            if has_positive:
                if "!!" in text or "!!!!" in text:
                    score += 10
                if "ğŸ‘ğŸ»" in text:
                    score += 5

        # 0~100 ë²”ìœ„ë¡œ í´ë¨í”„
        return max(0.0, min(100.0, score))

    def _class_probabilities_from_score(self, base_score: float) -> dict:
        """
        ë‹¨ì¼ ì ìˆ˜ì—ì„œ 5ê°œ í´ë˜ìŠ¤ í™•ë¥ ì„ ëŒ€ëµì ìœ¼ë¡œ ìƒì„±.
        ì¤‘ì•™(50)ì„ ê¸°ì¤€ìœ¼ë¡œ ì–‘/ìŒìˆ˜ ìª½ìœ¼ë¡œ ê¸°ìš¸ì–´ì§€ê²Œ ë¶„í¬ ìƒì„±.
        """
        # ì ìˆ˜ë¥¼ 0~4 êµ¬ê°„ìœ¼ë¡œ ë§¤í•‘
        target_idx = base_score / 25.0  # 0~4
        weights = []
        for i in range(5):
            # ê±°ë¦¬ê°€ ë©€ìˆ˜ë¡ ê°€ì¤‘ì¹˜ ê°ì†Œ (ì„ í˜•)
            dist = abs(target_idx - i)
            w = max(0.0, 1.5 - dist)  # 0~1.5
            weights.append(w)

        total = sum(weights) or 1.0
        probs = [w / total for w in weights]

        return {
            self.LABEL_MAPPING[i]: round(p * 100, 2)
            for i, p in enumerate(probs)
        }

    def analyze_text(self, text):
        try:
            base_score = self._score_with_rules(text)

            # ê°ì • ë¶„ë¥˜
            if base_score >= 75:
                sentiment = "ê¸ì •"
            elif base_score >= 55:
                sentiment = "ë‹¤ì†Œ ê¸ì •"
            elif base_score > 45 and base_score < 55:
                sentiment = "ì¤‘ë¦½"
            elif base_score >= 25:
                sentiment = "ë‹¤ì†Œ ë¶€ì •"
            else:
                sentiment = "ë¶€ì •"

            class_probs = self._class_probabilities_from_score(base_score)

            return {
                'score': base_score,
                'label': sentiment,
                'confidence': "ë†’ìŒ" if abs(base_score - 50) > 20 else "ì¤‘ê°„",
                'class_probabilities': class_probs,
            }

        except Exception as e:
            print(f"Error processing text: {str(e)}")
            return {
                'score': 50.0,
                'label': "ì¤‘ë¦½",
                'confidence': "ë‚®ìŒ"
            }

    def extract_top_keywords(self, texts: list[str], top_n: int = 3) -> list[str]:
        """
        í”¼ë“œ í…ìŠ¤íŠ¸ ì „ì²´ì—ì„œ ë§ì´ ë“±ì¥í•œ, ì˜ë¯¸ ìˆëŠ” í‚¤ì›Œë“œ ìƒìœ„ top_nê°œ ë°˜í™˜.
        ì¡°ì‚¬Â·ê°ì •ì‚¬ì „Â·stopword ì œì™¸ í›„ ë¹ˆë„ ê¸°ì¤€.
        """
        if not texts:
            return []

        # ê°ì • ì‚¬ì „ì— ìˆëŠ” ë‹¨ì–´ëŠ” í‚¤ì›Œë“œ í›„ë³´ì—ì„œ ì œì™¸ (ì˜ë¯¸ ìˆëŠ” ì£¼ì œì–´ ìœ„ì£¼)
        exclude = set(STOPWORDS)
        for key in ("positive", "negative", "very_negative", "swear_words"):
            exclude.update(self.EMOTION_DICT[key])

        # í•œê¸€Â·ì˜ë¬¸Â·ìˆ«ì ì—°ì†ë§Œ í† í°ìœ¼ë¡œ (2ì ì´ìƒ)
        token_re = re.compile(r"[ê°€-í£a-zA-Z0-9]{2,}")
        counter: Counter[str] = Counter()

        for text in texts:
            if not text or not isinstance(text, str):
                continue
            normalized = self.preprocess_text(text)
            tokens = token_re.findall(normalized)
            for t in tokens:
                t_lower = t.lower()
                if t_lower in exclude or t in exclude:
                    continue
                # ìˆ«ìë§Œ ìˆëŠ” í† í° ì œì™¸
                if t.isdigit():
                    continue
                counter[t_lower] += 1

        # ë¹ˆë„ ë‚´ë¦¼ì°¨ìˆœ, ë™ì ì´ë©´ ì›ë¬¸ ë“±ì¥ ìˆœì„œ ìœ ì§€í•˜ê³  ì‹¶ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë‘ê³  ìƒìœ„ nê°œ
        top = counter.most_common(top_n)
        return [word for word, _ in top]